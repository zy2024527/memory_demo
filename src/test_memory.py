import os
import logging
from crewai import Agent, Task, Crew, Process
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_openai import ChatOpenAI

# æŠ‘åˆ¶é”™è¯¯æ—¥å¿—
logging.getLogger().setLevel(logging.CRITICAL)
os.environ["PYTHONWARNINGS"] = "ignore"

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ["OPENAI_API_BASE"] = "http://localhost:11434/v1"
os.environ["OPENAI_API_KEY"] = "ollama"

# åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
try:
    import torch
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
except ImportError:
    device = 'cpu'

embeddings = HuggingFaceEmbeddings(
    model_name="BAAI/bge-small-zh-v1.5",
    model_kwargs={'device': device},
    encode_kwargs={'normalize_embeddings': True}
)

# åˆå§‹åŒ–LLM
llm = ChatOpenAI(
    model="ollama/qwen3:4b",
    base_url="http://localhost:11434/v1",
    api_key="ollama",
    temperature=0.3
)

# åˆ›å»ºç®€å•çš„æ™ºèƒ½ä½“
agent = Agent(
    role='æµ‹è¯•å‘˜',
    goal='æµ‹è¯•å†…å­˜åŠŸèƒ½',
    backstory="è´Ÿè´£æµ‹è¯•ç³»ç»ŸåŠŸèƒ½çš„ä¸“å®¶ã€‚",
    memory=True,
    verbose=True,
    llm=llm,
    embeddings=embeddings
)

# ç®€å•ä»»åŠ¡
task = Task(
    description="è¯´ä¸€å¥å…³äºç”µåŠ¨æ±½è½¦çš„è¯ã€‚",
    agent=agent,
    expected_output='ä¸€å¥ç®€çŸ­çš„è¯'
)

# åˆ›å»ºå›¢é˜Ÿ
crew = Crew(
    agents=[agent],
    tasks=[task],
    process=Process.sequential,
    verbose=True,
    memory=True
)

if __name__ == "__main__":
    print("ğŸ§ª æµ‹è¯•å†…å­˜åŠŸèƒ½...")
    try:
        result = crew.kickoff()
        print(f"âœ… æˆåŠŸï¼ç»“æœ: {result}")
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")