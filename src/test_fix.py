import os
from crewai import Agent, Task, Crew, Process, LLM
from openai import APIStatusError

# è®¾ç½®ç¯å¢ƒå˜é‡é¿å…OpenAIéªŒè¯
os.environ["OPENAI_API_KEY"] = "dummy-key"

# ä¿®å¤APIStatusErroråˆå§‹åŒ–é—®é¢˜
original_init = APIStatusError.__init__

def patched_init(self, message, *, response=None, body=None):
    if response is None:
        # åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„æ¨¡æ‹Ÿçš„responseå¯¹è±¡
        class MockRequest:
            method = "POST"
            url = "https://api.mock.com/v1/chat/completions"
            
        class MockResponse:
            status_code = 500
            headers = {}
            request = MockRequest()
            
            def json(self):
                return {"error": {"message": str(message)}}
                
            @property
            def text(self):
                return str({"error": {"message": str(message)}})
                
        response = MockResponse()
    
    if body is None:
        body = {"error": {"message": str(message)}}
    
    original_init(self, message, response=response, body=body)

APIStatusError.__init__ = patched_init

# æµ‹è¯•ä¿®å¤æ˜¯å¦æœ‰æ•ˆ
try:
    # å°è¯•åˆ›å»ºä¸€ä¸ªAPIStatusErroræ¥æµ‹è¯•ä¿®å¤
    error = APIStatusError("Test error message")
    print("âœ… APIStatusErrorä¿®å¤æˆåŠŸï¼")
    print(f"é”™è¯¯ä¿¡æ¯: {error}")
except Exception as e:
    print(f"âŒ APIStatusErrorä¿®å¤å¤±è´¥: {e}")

# ç®€å•çš„LLMé…ç½®æµ‹è¯•
llm = LLM(
    model="openai/Qwen/Qwen3-8B",
    provider="siliconflow",
    base_url="https://api.siliconflow.cn/v1",
    api_key="test-key",
    temperature=0,
)

print("âœ… LLMé…ç½®æˆåŠŸ")
print("ğŸ”§ ä¿®å¤éªŒè¯å®Œæˆ")