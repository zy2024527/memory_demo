import os
from crewai import Agent, Task, Crew, Process, LLM
# from openai import APIStatusError
# import sys
from crewai.memory import LongTermMemory, ShortTermMemory, EntityMemory
from crewai.memory.storage.rag_storage import RAGStorage
from crewai.memory.storage.ltm_sqlite_storage import LTMSQLiteStorage
from typing import List, Optional

# å¾ˆå¥½ï¼APIStatusErroré—®é¢˜å·²ç»è§£å†³äº†ã€‚ç°åœ¨æ˜¾ç¤ºçš„æ˜¯çœŸæ­£çš„é”™è¯¯ï¼š403é”™è¯¯ï¼Œè¡¨ç¤º"ä¸æ”¯æŒçš„å›½å®¶/åœ°åŒº"ã€‚è¿™æ˜¯SiliconFlow APIçš„åœ°ç†é™åˆ¶é—®é¢˜ï¼Œä¸æ˜¯ä»£ç é—®é¢˜ã€‚

# è®¾ç½®ç¯å¢ƒå˜é‡é¿å…OpenAIéªŒè¯
os.environ["OPENAI_API_KEY"] = "dummy-key"

# Configure storage path using environment variable
storage_path = os.getenv("CREWAI_STORAGE_DIR", "./storage")

# # ä¿®å¤APIStatusErroråˆå§‹åŒ–é—®é¢˜
# original_init = APIStatusError.__init__

# def patched_init(self, message, *, response=None, body=None):
#     if response is None:
#         # åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„æ¨¡æ‹Ÿçš„responseå¯¹è±¡
#         class MockRequest:
#             method = "POST"
#             url = "https://api.mock.com/v1/chat/completions"
            
#         class MockResponse:
#             status_code = 500
#             headers = {}
#             request = MockRequest()
            
#             def json(self):
#                 return {"error": {"message": str(message)}}
                
#             @property
#             def text(self):
#                 return str({"error": {"message": str(message)}})
                
#         response = MockResponse()
    
#     if body is None:
#         body = {"error": {"message": str(message)}}
    
#     original_init(self, message, response=response, body=body)

# APIStatusError.__init__ = patched_init


llm = LLM(
    model="openai/Qwen/Qwen3-8B",
    provider="siliconflow",
    base_url="https://api.siliconflow.cn/v1",
    api_key="sk-sbdwwnjulncostljtkbapfltvfwdzannjhpumoqbglgjewea",
    temperature=0,
)

embeddings = {
    "provider": "siliconflow",
    "config": {
        "model": 'BAAI/bge-large-zh-v1.5',
        "base_url": 'https://api.siliconflow.cn/v1',
        "api_key": 'sk-sbdwwnjulncostljtkbapfltvfwdzannjhpumoqbglgjewea'
    }
}


# å®šä¹‰æ™ºèƒ½ä½“
researcher = Agent(
    role='å¸‚åœºç ”ç©¶å‘˜',
    goal='æ”¶é›†ç”µåŠ¨æ±½è½¦å¸‚åœºæ•°æ®',
    backstory="ä¸“æ³¨äºæ–°èƒ½æºæ±½è½¦é¢†åŸŸçš„åˆ†æå¸ˆã€‚",
    verbose=True,
    llm=llm
)

analyst = Agent(
    role='æ•°æ®åˆ†æå¸ˆ',
    goal='åˆ†æå¸‚åœºè¶‹åŠ¿',
    backstory="æ“…é•¿æ•°æ®å¤„ç†å’Œåˆ†æçš„ä¸“å®¶ã€‚",
    verbose=True,
    llm=llm
)

# ç®€åŒ–ä»»åŠ¡ä»¥é¿å…é•¿æ—¶é—´è¿è¡Œ
research_task = Task(
    description="æ”¶é›†2024å¹´ç”µåŠ¨æ±½è½¦å¸‚åœºçš„åŸºæœ¬ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä¸»è¦å‚å•†å’ŒæŠ€æœ¯å‘å±•ã€‚",
    agent=researcher,
    expected_output='ç®€è¦çš„å¸‚åœºæ¦‚è¿°'
)

analysis_task = Task(
    description="åˆ†æç”µåŠ¨æ±½è½¦å¸‚åœºçš„ä¸€ä¸ªä¸»è¦è¶‹åŠ¿ã€‚",
    agent=analyst,
    expected_output='ç®€è¦çš„è¶‹åŠ¿åˆ†æ'
)

# åˆ›å»ºå›¢é˜Ÿ
ev_crew = Crew(
    agents=[researcher, analyst],
    tasks=[research_task, analysis_task],
    process=Process.sequential,
    verbose=True,
    memory=True,
    long_term_memory=LongTermMemory(
        storage=LTMSQLiteStorage(
            db_path="{storage_path}/ltm_memory.db".format(storage_path=storage_path)
        )
    ),
    # Short-term memory for current context using RAG
    short_term_memory = ShortTermMemory(
        storage = RAGStorage(
                embedder_config={
                    "provider": "ollama",
                    "config": {
                        "model": 'nomic-embed-text'
                    }
                },
                type="short_term",
                path=f"{storage_path}"
        )
    ),

    # Entity memory for tracking key information about entities
    entity_memory = EntityMemory(
        storage=RAGStorage(
            embedder_config={
                "provider": "ollama",
                "config": {
                    "model": 'nomic-embed-text'
                }
            },
            type="short_term",
            path=f"{storage_path}"
        )
    ),
)

# è¿è¡Œå›¢é˜Ÿ
if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹ç”µåŠ¨æ±½è½¦å¸‚åœºè°ƒç ”ä»»åŠ¡...")
    print("ğŸ“‹ ä½¿ç”¨æ¨¡å‹: openai/Qwen/Qwen3-8B via siliconflow")
    print("ğŸ”¤ åµŒå…¥æ¨¡å‹: BAAI/bge-large-zh-v1.5")
    print("ğŸ”§ APIStatusErrorå·²ä¿®å¤")
    
    try:
        result = ev_crew.kickoff()
        print("\n" + "="*50)
        print("âœ… ä»»åŠ¡å®Œæˆï¼")
        print("="*50)
        print(result)
        
    except Exception as e:
        print(f"âŒ è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
